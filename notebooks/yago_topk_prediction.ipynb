{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query answering on YAGO3-10\n",
    "\n",
    "In this notebook we will show how to use the BESS-KGE package to perform knowledge graph completion on the YAGO3-10 dataset, a subset of [YAGO3](https://yago-knowledge.org/downloads/yago-3) (Yet Another Great Ontology 3) containing only entities with at least ten relations associated to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+ssh://git@github.com/graphcore-research/bess-kge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ctypes\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import poptorch\n",
    "import torch\n",
    "\n",
    "from besskge.batch_sampler import RigidShardedBatchSampler\n",
    "from besskge.bess import EmbeddingMovingBessKGE, TopKQueryBessKGE\n",
    "from besskge.dataset import KGDataset\n",
    "from besskge.embedding import MarginBasedInitializer\n",
    "from besskge.loss import MarginRankingLoss, LogSigmoidLoss\n",
    "from besskge.metric import Evaluation\n",
    "from besskge.negative_sampler import (\n",
    "    PlaceholderNegativeSampler,\n",
    "    RandomShardedNegativeSampler,\n",
    ")\n",
    "from besskge.scoring import ComplEx\n",
    "from besskge.sharding import PartitionedTripleSet, Sharding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and preprocess the dataset with the built-in method of `KGDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yago = KGDataset.build_yago310(root=pathlib.Path(\"../datasets/yago310/\"))\n",
    "\n",
    "print(f\"Number of entities: {yago.n_entity}\\n\")\n",
    "print(f\"Number of relation types: {yago.n_relation_type}\\n\")\n",
    "print(f\"Number of triples: \\n training: {yago.triples['train'].shape[0]} \\n validation/test: {yago.triples['validation'].shape[0]}\\n\")\n",
    "\n",
    "# Print example triple\n",
    "ex_triple_id = 2500\n",
    "ex_triple = yago.triples[\"train\"][ex_triple_id]\n",
    "print(f'Example triple: {yago.entity_dict[ex_triple[0]], yago.relation_dict[ex_triple[1]], yago.entity_dict[ex_triple[2]]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train on 4 IPUs, so we construct a sharding of the entity table in 4 parts. The entity sharding induces a sharding of the triples into 4*4=16 shardpairs, based on the shard of head and tail entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "n_shard = 4\n",
    "\n",
    "sharding = Sharding.create(yago.n_entity, n_shard=n_shard, seed=seed)\n",
    "print(f\"Global entity IDs on {n_shard} shards:\")\n",
    "print(sharding.shard_and_idx_to_entity)\n",
    "\n",
    "# The global entity IDs can be recovered, as a function of the shard ID and the local ID on the shard, by\n",
    "print(\"\\nReconstructed global entity IDs:\")\n",
    "print(sharding.shard_and_idx_to_entity[sharding.entity_to_shard, sharding.entity_to_idx])\n",
    "\n",
    "train_triples = PartitionedTripleSet.create_from_dataset(yago, \"train\", sharding)\n",
    "\n",
    "print(\"\\nNumber of triples per (h,t) shardpair:\")\n",
    "print(train_triples.triple_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To iterate over the sharded set of triples we use a batch sampler.\n",
    "`RigidShardedBatchSampler` consumes, at each step, the same number of triples from all 16 shardpairs\n",
    "(resampling from the shorter ones, until the longest one is completed).\n",
    "\n",
    "To sample negatives during training we use a negative sampler. \n",
    "`RandomShardedNegativeSampler` constructs, for each triple, negative samples by sampling random corrupted entities.\n",
    "\n",
    "See the [biogk_training_inference](biokg_training_inference.ipynb) notebook for more details on these classes' options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_iterations = 10\n",
    "accum_factor = 5\n",
    "shard_bs = 240\n",
    "neg_sampler = RandomShardedNegativeSampler(n_negative=1, sharding=sharding, seed=seed, corruption_scheme=\"ht\", local_sampling=False, flat_negative_format=False)\n",
    "bs = RigidShardedBatchSampler(partitioned_triple_set=train_triples, negative_sampler=neg_sampler, shard_bs=shard_bs, batches_per_step=device_iterations*accum_factor, seed=seed, hrt_freq_weighting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = poptorch.Options()\n",
    "options.replication_factor = sharding.n_shard\n",
    "options.deviceIterations(device_iterations)\n",
    "options.Training.gradientAccumulation(accum_factor)\n",
    "options._popart.setPatterns(dict(RemoveAllReducePattern=True))\n",
    "\n",
    "# Construct the dataloader with the dedicated utility function\n",
    "train_dl = bs.get_dataloader(options=options, shuffle=True, num_workers=5, persistent_workers=True)\n",
    "\n",
    "# Example batch\n",
    "batch = next(iter(train_dl))\n",
    "for k,v in batch.items():\n",
    "    print(f\"{k:<12} {str(v.shape):<30}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the **ComplEx** KGE model with real embedding size 256 and **logsigmoid** loss function, using the `EmbeddingMovingBessKGE` distribution scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marg_rank_loss_fn = LogSigmoidLoss(margin=12.0, negative_adversarial_sampling=True)\n",
    "emb_initializer = MarginBasedInitializer(margin=marg_rank_loss_fn.margin)\n",
    "complex_score_fn = ComplEx(negative_sample_sharing=True, sharding=sharding, n_relation_type=yago.n_relation_type, embedding_size=256,\n",
    "                           entity_intializer=emb_initializer, relation_intializer=emb_initializer)\n",
    "model = EmbeddingMovingBessKGE(sharding=sharding, negative_sampler=neg_sampler, score_fn=complex_score_fn,\n",
    "                               loss_fn=marg_rank_loss_fn)\n",
    "print(f\"# model parameters: {model.n_embedding_parameters}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = poptorch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.001,\n",
    "        weight_decay=0.0,\n",
    "        accum_type=torch.float32,\n",
    "        first_order_momentum_accum_type=torch.float32,\n",
    "        second_order_momentum_accum_type=torch.float32,\n",
    "    )\n",
    "\n",
    "poptorch_model = poptorch.trainingModel(model, options=options, optimizer=opt)\n",
    "\n",
    "# The variable entity_embedding needs to hold different values on each replica,\n",
    "# corresponding to the shards of the entity embedding table\n",
    "poptorch_model.entity_embedding.replicaGrouping(\n",
    "            poptorch.CommGroupType.NoGrouping,\n",
    "            0,\n",
    "            poptorch.VariableRetrievalMode.OnePerGroup,\n",
    "        )\n",
    "\n",
    "# Graph compilation\n",
    "_ = batch.pop(\"triple_mask\")\n",
    "res = poptorch_model(**{k: v.flatten(end_dim=1) for k, v in batch.items()})\n",
    "\n",
    "n_epochs = 25\n",
    "\n",
    "for ep in range(n_epochs):\n",
    "    ep_start_time = time.time()\n",
    "    ep_log = []\n",
    "    for batch in iter(train_dl):\n",
    "        step_start_time = time.time()\n",
    "        triple_mask = batch.pop(\"triple_mask\")\n",
    "        res = poptorch_model(**{k: v.flatten(end_dim=1) for k, v in batch.items()})\n",
    "        ep_log.append(dict(loss=res[\"loss\"], step_time=(time.time()-step_start_time)))\n",
    "    print(f\"Epoch {ep+1} loss: {torch.concat([v['loss'] for v in ep_log]).mean().item():.6f}\")\n",
    "    print(f\"Epoch duration (sec): {(time.time() - ep_start_time):.5f}, average step time (sec): {np.mean([v['step_time'] for v in ep_log]):.5f}\")\n",
    "\n",
    "poptorch_model.detachFromDevice()\n",
    "del train_dl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation, for each query we want to predict the top-10 most likely tails among all the 123k+ entities in the knowledge graph. We can do so by using the `TopKQueryBessKGE` distribution scheme of BESS.\n",
    "\n",
    "Since there are no specific tail candidates to sample, our dataloader does not need to pass negative indices to the IPUs. We therefore use the `PlaceholderNegativeSampler` class.\n",
    "\n",
    "When using `TopKQueryBessKGE` we partition triples based just on the shard of the head entitiy (or the tail entity, if we wanted to predict heads), specifying `partition_mode='h_shard'` when constructing the `PartitionedTripleSet`. Moreover, we set the option `return_triple_idx=True` to return the indices of the triples in the batch with respect to the ordered list `validation_triples.triples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_iterations = 3\n",
    "shard_bs = 480\n",
    "\n",
    "validation_triples = PartitionedTripleSet.create_from_dataset(yago, \"validation\", sharding, partition_mode=\"h_shard\")\n",
    "candidate_sampler = PlaceholderNegativeSampler(corruption_scheme=\"t\", seed=seed)\n",
    "bs_valid = RigidShardedBatchSampler(partitioned_triple_set=validation_triples, negative_sampler=candidate_sampler, shard_bs=shard_bs, batches_per_step=device_iterations,\n",
    "                                    seed=seed, duplicate_batch=False, return_triple_idx=True)\n",
    "\n",
    "print(\"Number of triples per h_shard:\")\n",
    "print(validation_triples.triple_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_options = poptorch.Options()\n",
    "val_options.replication_factor = n_shard\n",
    "val_options.deviceIterations(bs_valid.batches_per_step)\n",
    "val_options.outputMode(poptorch.OutputMode.All)\n",
    "\n",
    "valid_dl = bs_valid.get_dataloader(options=val_options, shuffle=False, num_workers=5, persistent_workers=True)\n",
    "\n",
    "# Example batch\n",
    "batch = next(iter(valid_dl))\n",
    "for k,v in batch.items():\n",
    "    print(f\"{k:<12} {str(v.shape):<30}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each of the 3 batches returned by a call to the dataloader has a microbatch size of 480 triples. Notice that, when constructing the partitioned triple set with `partition_mode='h_shard'`, the tensor `head` will contain the **local** entity IDs in the corresponding shard, while `tail` contains the **global** IDs of the ground truth tails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_sorted = yago.triples[\"validation\"][validation_triples.triple_sort_idx]\n",
    "triple_sorted[:,0] = sharding.entity_to_idx[triple_sorted[:,0]]\n",
    "np.all(triple_sorted == validation_triples.triples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compile the inference `TopKQueryBessKGE` model. We use the `Evaluation` class to specify which metrics we want to compute (see `besskge.metric`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set worst_rank_infty=True to assign a reciprocal rank of 0 if the ground truth tail is not among the top-10 predicted tails (otherwise the reciprocal rank would be 1/11).\n",
    "evaluation = Evaluation([\"mrr\", \"hits@3\", \"hits@10\"], worst_rank_infty=True)\n",
    "inf_model = TopKQueryBessKGE(k=10, sharding=sharding, candidate_sampler=candidate_sampler, score_fn=complex_score_fn, evaluation=evaluation)\n",
    "\n",
    "poptorch_inf_model = poptorch.inferenceModel(inf_model, options=val_options)\n",
    "\n",
    "poptorch_inf_model.entity_embedding.replicaGrouping(\n",
    "            poptorch.CommGroupType.NoGrouping,\n",
    "            0,\n",
    "            poptorch.VariableRetrievalMode.OnePerGroup,\n",
    "        )\n",
    "\n",
    "_ = batch.pop(\"triple_mask\")\n",
    "_ = batch.pop(\"triple_idx\")\n",
    "res = poptorch_inf_model(**{k: v.flatten(end_dim=1) for k, v in batch.items()})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now iterate over the validation set to compute the predictions and the corresponding metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_log = []\n",
    "start_time = time.time()\n",
    "n_val_queries = 0\n",
    "for batch_val in iter(valid_dl):\n",
    "    triple_mask = batch_val.pop(\"triple_mask\")\n",
    "    triple_idx = batch_val.pop(\"triple_idx\")\n",
    "    step_start_time = time.time()\n",
    "    res = poptorch_inf_model(**{k: v.flatten(end_dim=1) for k, v in batch_val.items()})\n",
    "    \n",
    "    n_val_queries += triple_mask.sum()\n",
    "    # Filter out padding triples using triple_mask\n",
    "    val_log.append({k: v[triple_mask.flatten()].sum() for k, v in res[\"metrics\"].items()})\n",
    "\n",
    "print(f\"Validation time (sec): {(time.time() - start_time):.5f}\\n\")\n",
    "\n",
    "for metric in val_log[0].keys():\n",
    "    reduced_metric = sum([l[metric] for l in val_log]) / n_val_queries\n",
    "    print(\"%s : %f\" % (metric, reduced_metric))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mean reciprocal rank of 0.2 means that, on average, the correct tail is the 5th most likely one predicted by the model.\n",
    "\n",
    "We can check that this is correct by computing the MRR directly on the un-sharded triples, on CPU..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_table = complex_score_fn.entity_embedding.detach()[sharding.entity_to_shard, sharding.entity_to_idx]\n",
    "rel_table = complex_score_fn.relation_embedding.detach()\n",
    "\n",
    "scores = complex_score_fn.score_tails(ent_table[yago.triples[\"validation\"][:,0]], torch.from_numpy(yago.triples[\"validation\"][:,1]), ent_table.unsqueeze(0))\n",
    "top_k = torch.topk(scores, dim=-1, k=10)\n",
    "rec_rank_true = evaluation.metrics_from_indices(torch.from_numpy(yago.triples[\"validation\"][:,2]), top_k.indices.squeeze())[\"mrr\"]\n",
    "\n",
    "print(f\"CPU validation MRR: {rec_rank_true.mean():.6f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and have a look at some of the predictions made by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prediction(val_triple_id):\n",
    "    # Recover the non-padding triples seen in the last batch using triple_idx and triple_mask\n",
    "    triples = yago.triples[\"validation\"][validation_triples.triple_sort_idx][triple_idx[triple_mask]]\n",
    "    h,r,t = triples[val_triple_id]\n",
    "    # Top-10 tails predicted by the KGE model\n",
    "    top10_t = res[\"topk_global_id\"][triple_mask.flatten()][val_triple_id]\n",
    "    \n",
    "    print(f'Example query: ({yago.entity_dict[h]}, {yago.relation_dict[r]}, ?)\\n')\n",
    "    print(f\"Correct tail: {yago.entity_dict[t]}\\n\")\n",
    "    print(f\"10 most likely predicted tails:\")\n",
    "    for i, pt in enumerate(top10_t):\n",
    "        print(f\"{i+1}) {yago.entity_dict[pt]}\" + (\"   <-----\" if pt == t else \"\"))\n",
    "    print(\"\\n\")\n",
    "\n",
    "check_prediction(1615)\n",
    "check_prediction(1990)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
